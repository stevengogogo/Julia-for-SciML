[
  {
    "objectID": "index_sciml-intro.html",
    "href": "index_sciml-intro.html",
    "title": "Part II: SciML Packages",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Session Info",
    "section": "",
    "text": "Place: Blocker 220, Texas A&M University (Map)\nTime: 10:00 am - 12:00 pm. October 25, 2022\n(Latest information is on TAMIDS page)"
  },
  {
    "objectID": "index.html#presenter",
    "href": "index.html#presenter",
    "title": "Session Info",
    "section": "Presenter",
    "text": "Presenter\n\nSteven Shao-Ting Chiu — Ph.D. Student, Department of Electrical Engineering, Texas A&M University\nAdvisor: Dr. Ulisses Braga-Neto"
  },
  {
    "objectID": "index.html#background-and-objectives",
    "href": "index.html#background-and-objectives",
    "title": "Session Info",
    "section": "Background and Objectives",
    "text": "Background and Objectives\nJulia (https://julialang.org/) is a generic programming language designed for high-performance computing. It solves the “two language problem” that typically occurs in scientific computing. Julia is dynamically typed like scripting language such as Python and can be compiled into native machine code. Besides, composablility via multiple dispatches makes Julia works well on the integration across packages. SciML (https://sciml.ai/) is an open-source software for scientific machine learning based on the Julia language that combines machine learning and scientific computing by integrating numerous standalone packages. Notebly, Julia is an open-source project under an MIT license.\nThis worhshop aims to introduce the potential of the Scientific Machine Learning field with Julia programming language. First, we will give an introductory overview of the Julia programming language and explore the Julia SciML ecosystem as an example of its application.\nBoth sessions will include presentations and hands-on sessions. Prior knowledge of Python is recommended, and participants are encouraged to bring their own laptops."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Session Info",
    "section": "Schedule",
    "text": "Schedule\n\nSchedule (Total: 2hrs)\n\n\nTime\nContent\n\n\n\n\n25 min\nIntroduction to the Julia Programming Language\n\n\n25 min\nThe Julia SciML Ecosystem\n\n\n10 min\nBreak\n\n\n30 min\nHands-on session with nerual differential equation\n\n\n30 min\nHands-on session with SciML application"
  },
  {
    "objectID": "index.html#access-to-this-webpage",
    "href": "index.html#access-to-this-webpage",
    "title": "Session Info",
    "section": "Access to this webpage",
    "text": "Access to this webpage\n\n\n\nFigure 1: https://stevengogogo.github.io/Julia-for-SciML\n\n\n\nHands-on session\n\n\n\n\n\n\nDownload hands-on tutorials (Repo, zip)\nView on"
  },
  {
    "objectID": "SLIDE_julia-intro.html#what-is-julia",
    "href": "SLIDE_julia-intro.html#what-is-julia",
    "title": "Introduction to Julia Language",
    "section": "What is Julia?",
    "text": "What is Julia?\n\n\n\nJulia is a generic high-performance programming language1\n\nJust-In-Time (JIT) compilation\nMultiple dispatch creates type-stability\n\nVia multiple dispatch, different programming patterns can be adapted to the application.\nJulia supports high-level syntax that is approachable.\n\n\n\n\n\n\n\n\n\n\nInstallation: Julia Intro"
  },
  {
    "objectID": "SLIDE_julia-intro.html#a-quick-look-at-multiple-dispatch",
    "href": "SLIDE_julia-intro.html#a-quick-look-at-multiple-dispatch",
    "title": "Introduction to Julia Language",
    "section": "A quick look at multiple dispatch",
    "text": "A quick look at multiple dispatch\nA Generic function\njulia> function multiply(a,b)\n           return a*b\n       end\nmultiply (generic function with 1 method)"
  },
  {
    "objectID": "SLIDE_julia-intro.html#a-quick-look-at-multiple-dispatch-1",
    "href": "SLIDE_julia-intro.html#a-quick-look-at-multiple-dispatch-1",
    "title": "Introduction to Julia Language",
    "section": "A quick look at multiple dispatch",
    "text": "A quick look at multiple dispatch\n\nType inference in Julia solves the optimized data type2.\n\nInteger Input\njulia> @code_llvm multiply(1, 1)\n;  @ REPL[1]:1 within `multiply`\ndefine i64 @julia_multiply_660(i64 signext %0, i64 signext %1) #0 {\ntop:\n;  @ REPL[1]:2 within `multiply`\n; ┌ @ int.jl:88 within `*`\n   %2 = mul i64 %1, %0\n; └\n  ret i64 %2\n\n@code_llvm shows the processed script in intermediate presentation (IR).\n\n\nThis is my note.\n\nIt can contain Markdown\nlike this list"
  },
  {
    "objectID": "SLIDE_julia-intro.html#a-quick-look-at-multiple-dispatch-2",
    "href": "SLIDE_julia-intro.html#a-quick-look-at-multiple-dispatch-2",
    "title": "Introduction to Julia Language",
    "section": "A quick look at multiple dispatch",
    "text": "A quick look at multiple dispatch\n\njulia> @code_llvm multiply(2.0,2)\n;  @ REPL[1]:1 within `multiply`\ndefine double @julia_multiply_208(double %0, i64 signext %1) #0 {\ntop:\n;  @ REPL[1]:2 within `multiply`\n; ┌ @ promotion.jl:389 within `*`\n; │┌ @ promotion.jl:359 within `promote`\n; ││┌ @ promotion.jl:336 within `_promote`\n; │││┌ @ number.jl:7 within `convert`\n; ││││┌ @ float.jl:146 within `Float64`\n       %2 = sitofp i64 %1 to double\n# Skip\n  ret double %3\n}"
  },
  {
    "objectID": "SLIDE_julia-intro.html#significant-features",
    "href": "SLIDE_julia-intro.html#significant-features",
    "title": "Introduction to Julia Language",
    "section": "Significant Features",
    "text": "Significant Features\n\nJulia Base and standard library are written in Julia itself.\n\n\n\nJulia is always Just-in-Time (JIT) compiled\n\n\n\n\nMultiple dispatch allows many conbinatoins of argument types\n\nApproaching the speed of statically-compiled language like C/Fortran3\n\n\n\n\nWhy Julia is fast?4\n\nJIT\nType inference\nType specialization in functions"
  },
  {
    "objectID": "SLIDE_julia-intro.html#ecosystem",
    "href": "SLIDE_julia-intro.html#ecosystem",
    "title": "Introduction to Julia Language",
    "section": "Ecosystem",
    "text": "Ecosystem"
  },
  {
    "objectID": "SLIDE_julia-intro.html#references",
    "href": "SLIDE_julia-intro.html#references",
    "title": "Introduction to Julia Language",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n1. Bezanson, J., Edelman, A., Karpinski, S., and Shah, V.B. (2017). Julia: A fresh approach to numerical computing. SIAM review 59, 65–98.\n\n\n2. Nash, J. (2016). Inference Convergence Algorithm in Julia - Julia Computing.\n\n\n3. Julia Documentation \\(\\cdot\\) The Julia Language.\n\n\n4. Rackauckas, C. (2022). Parallel computing and scientific machine learning (SciML): Methods and applications 10.5281/zenodo.6917234."
  },
  {
    "objectID": "hands-on/julia_basics.html",
    "href": "hands-on/julia_basics.html",
    "title": "Julia Basics",
    "section": "",
    "text": "[1]\n\nusing Pkg\nPkg.activate(\"tutorial\")\n\n\n\n\n\nReferences\n\n[1] Rackauckas, C. A Deep Introduction to Julia for Data Science and Scientific Computing. http://ucidatascienceinitiative.github.io/IntroToJulia/."
  },
  {
    "objectID": "hands-on/infectious_model.html",
    "href": "hands-on/infectious_model.html",
    "title": "Example: Infectious Model",
    "section": "",
    "text": "using Pkg\nPkg.activate(\"tutorial\")\nPkg.instantiate()\n\n  Activating project at `~/Documents/GitHub/Julia-for-SciML/hands-on/tutorial`\n\n\n\ncd(@__DIR__)\nusing Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n\n# Single experiment, move to ensemble further on\n# Some good parameter values are stored as comments right now\n# because this is really good practice\n\nusing OrdinaryDiffEq\nusing ModelingToolkit\nusing DataDrivenDiffEq\nusing LinearAlgebra, DiffEqSensitivity, Optim\nusing DiffEqFlux, Flux\nusing Plots\ngr()\n\nfunction corona!(du,u,p,t)\n    S,E,I,R,N,D,C = u\n    F, β0,α,κ,μ,σ,γ,d,λ = p\n    dS = -β0*S*F/N - β(t,β0,D,N,κ,α)*S*I/N -μ*S # susceptible\n    dE = β0*S*F/N + β(t,β0,D,N,κ,α)*S*I/N -(σ+μ)*E # exposed\n    dI = σ*E - (γ+μ)*I # infected\n    dR = γ*I - μ*R # removed (recovered + dead)\n    dN = -μ*N # total population\n    dD = d*γ*I - λ*D # severe, critical cases, and deaths\n    dC = σ*E # +cumulative cases\n\n    du[1] = dS; du[2] = dE; du[3] = dI; du[4] = dR\n    du[5] = dN; du[6] = dD; du[7] = dC\nend\nβ(t,β0,D,N,κ,α) = β0*(1-α)*(1-D/N)^κ\nS0 = 14e6\nu0 = [0.9*S0, 0.0, 0.0, 0.0, S0, 0.0, 0.0]\np_ = [10.0, 0.5944, 0.4239, 1117.3, 0.02, 1/3, 1/5,0.2, 1/11.2]\nR0 = p_[2]/p_[7]*p_[6]/(p_[6]+p_[5])\ntspan = (0.0, 21.0)\nprob = ODEProblem(corona!, u0, tspan, p_)\nsolution = solve(prob, Vern7(), abstol=1e-12, reltol=1e-12, saveat = 1)\n\ntspan2 = (0.0,60.0)\nprob = ODEProblem(corona!, u0, tspan2, p_)\nsolution_extrapolate = solve(prob, Vern7(), abstol=1e-12, reltol=1e-12, saveat = 1)\n\n# Ideal data\ntsdata = Array(solution)\n# Add noise to the data\nnoisy_data = tsdata + Float32(1e-5)*randn(eltype(tsdata), size(tsdata))\n\nplot(abs.(tsdata-noisy_data)')\n\n### Neural ODE\n\nann_node = FastChain(FastDense(7, 64, tanh),FastDense(64, 64, tanh), FastDense(64, 64, tanh), FastDense(64, 7))\np = Float64.(initial_params(ann_node))\n\nfunction dudt_node(u,p,t)\n    S,E,I,R,N,D,C = u\n    F,β0,α,κ,μ,σ,γ,d,λ = p_\n    dS,dE,dI,dR,dD = ann_node([S/N,E,I,R,N,D/N,C],p)\n\n    dN = -μ*N # total population\n    dC = σ*E # +cumulative cases\n\n    [dS,dE,dI,dR,dN,dD,dC]\nend\nprob_node = ODEProblem(dudt_node, u0, tspan, p)\ns = concrete_solve(prob_node, Tsit5(), u0, p, saveat = solution.t)\n\nfunction predict(θ)\n    Array(concrete_solve(prob_node, Vern7(), u0, θ, saveat = 1,\n                         abstol=1e-6, reltol=1e-6,\n                         sensealg = InterpolatingAdjoint(autojacvec=ReverseDiffVJP())))\nend\n\n# No regularisation right now\nfunction loss(θ)\n    pred = predict(θ)\n    sum(abs2, (noisy_data[2:4,:] .- pred[2:4,:])), pred # + 1e-5*sum(sum.(abs, params(ann)))\nend\n\nloss(p)\n\nconst losses = []\ncallback(θ,l,pred) = begin\n    push!(losses, l)\n    if length(losses)%50==0\n        println(losses[end])\n    end\n    false\nend\n\nres1_node = DiffEqFlux.sciml_train(loss, p, ADAM(0.01), cb=callback, maxiters = 500)\nres2_node = DiffEqFlux.sciml_train(loss, res1_node.minimizer, BFGS(initial_stepnorm=0.01), cb=callback, maxiters = 10000)\n\nprob_node2 = ODEProblem(dudt_node, u0, tspan, res2_node.minimizer)\ns = solve(prob_node2, Tsit5(), saveat = 1)\nscatter(solution, vars=[2,3,4], label=[\"True Exposed\" \"True Infected\" \"True Recovered\"])\nplot!(s, vars=[2,3,4], label=[\"Estimated Exposed\" \"Estimated Infected\" \"Estimated Recovered\"])\n\n# Plot the losses\nplot(losses, yaxis = :log, xaxis = :log, xlabel = \"Iterations\", ylabel = \"Loss\")\n\n# Extrapolate out\nprob_node_extrapolate = ODEProblem(dudt_node,u0, tspan2, res2_node.minimizer)\n_sol_node = solve(prob_node_extrapolate, Vern7(), abstol=1e-12, reltol=1e-12, saveat = 1)\np_node = scatter(solution_extrapolate, vars=[2,3,4], legend = :topleft, label=[\"True Exposed\" \"True Infected\" \"True Recovered\"], title=\"Neural ODE Extrapolation\")\nplot!(p_node,_sol_node, lw=5, vars=[2,3,4], label=[\"Estimated Exposed\" \"Estimated Infected\" \"Estimated Recovered\"])\nplot!(p_node,[20.99,21.01],[0.0,maximum(hcat(Array(solution_extrapolate[2:4,:]),Array(_sol_node[2:4,:])))],lw=5,color=:black,label=\"Training Data End\")\n\nsavefig(\"neuralode_extrapolation.png\")\nsavefig(\"neuralode_extrapolation.pdf\")\n\n### Universal ODE Part 1\n\nann = FastChain(FastDense(3, 64, tanh),FastDense(64, 64, tanh), FastDense(64, 1))\np = Float64.(initial_params(ann))\n\nfunction dudt_(u,p,t)\n    S,E,I,R,N,D,C = u\n    F, β0,α,κ,μ,σ,γ,d,λ = p_\n    z = ann([S/N,I,D/N],p) # Exposure does not depend on exposed, removed, or cumulative!\n    dS = -β0*S*F/N - z[1] -μ*S # susceptible\n    dE = β0*S*F/N + z[1] -(σ+μ)*E # exposed\n    dI = σ*E - (γ+μ)*I # infected\n    dR = γ*I - μ*R # removed (recovered + dead)\n    dN = -μ*N # total population\n    dD = d*γ*I - λ*D # severe, critical cases, and deaths\n    dC = σ*E # +cumulative cases\n\n    [dS,dE,dI,dR,dN,dD,dC]\nend\nprob_nn = ODEProblem(dudt_,u0, tspan, p)\ns = concrete_solve(prob_nn, Tsit5(), u0, p, saveat = 1)\n\nplot(solution, vars=[2,3,4])\nplot!(s[2:4,:]')\n\nfunction predict(θ)\n    Array(concrete_solve(prob_nn, Vern7(), u0, θ, saveat = solution.t,\n                         abstol=1e-6, reltol=1e-6,\n                         sensealg = InterpolatingAdjoint(autojacvec=ReverseDiffVJP())))\nend\n\n# No regularisation right now\nfunction loss(θ)\n    pred = predict(θ)\n    sum(abs2, noisy_data[2:4,:] .- pred[2:4,:]), pred # + 1e-5*sum(sum.(abs, params(ann)))\nend\n\nloss(p)\n\nconst losses = []\ncallback(θ,l,pred) = begin\n    push!(losses, l)\n    if length(losses)%50==0\n        println(losses[end])\n    end\n    false\nend\n\nres1_uode = DiffEqFlux.sciml_train(loss, p, ADAM(0.01), cb=callback, maxiters = 500)\nres2_uode = DiffEqFlux.sciml_train(loss, res1_uode.minimizer, BFGS(initial_stepnorm=0.01), cb=callback, maxiters = 10000)\n\nloss(res2_uode.minimizer)\n\nprob_nn2 = ODEProblem(dudt_,u0, tspan, res2_uode.minimizer)\nuode_sol = solve(prob_nn2, Tsit5(), saveat = 1)\nplot(solution, vars=[2,3,4])\nplot!(uode_sol, vars=[2,3,4])\n\n# Plot the losses\nplot(losses, yaxis = :log, xaxis = :log, xlabel = \"Iterations\", ylabel = \"Loss\")\n\n# Collect the state trajectory and the derivatives\nX = noisy_data\n# Ideal derivatives\nDX = Array(solution(solution.t, Val{1}))\n\n# Extrapolate out\nprob_nn2 = ODEProblem(dudt_,u0, tspan2, res2_uode.minimizer)\n_sol_uode = solve(prob_nn2, Vern7(), abstol=1e-12, reltol=1e-12, saveat = 1)\np_uode = scatter(solution_extrapolate, vars=[2,3,4], legend = :topleft, label=[\"True Exposed\" \"True Infected\" \"True Recovered\"], title=\"Universal ODE Extrapolation\")\nplot!(p_uode,_sol_uode, lw = 5, vars=[2,3,4], label=[\"Estimated Exposed\" \"Estimated Infected\" \"Estimated Recovered\"])\nplot!(p_uode,[20.99,21.01],[0.0,maximum(hcat(Array(solution_extrapolate[2:4,:]),Array(_sol_uode[2:4,:])))],lw=5,color=:black,label=\"Training Data End\")\n\nsavefig(\"universalode_extrapolation.png\")\nsavefig(\"universalode_extrapolation.pdf\")\n\n### Universal ODE Part 2: SInDy to Equations\n\n# Create a Basis\n@variables u[1:3]\n# Lots of polynomials\npolys = Operation[]\nfor i ∈ 0:2, j ∈ 0:2, k ∈ 0:2\n    push!(polys, u[1]^i * u[2]^j * u[3]^k)\nend\n\n# And some other stuff\nh = [cos.(u)...; sin.(u)...; unique(polys)...]\nbasis = Basis(h, u)\n\nX = noisy_data\n# Ideal derivatives\nDX = Array(solution(solution.t, Val{1}))\nS,E,I,R,N,D,C = eachrow(X)\nF,β0,α,κ,μ,_,γ,d,λ = p_\nL = β.(0:tspan[end],β0,D,N,κ,α).*S.*I./N\nL̂ = vec(ann([S./N I D./N]',res2_uode.minimizer))\nX̂ = [S./N I D./N]'\n\nscatter(L,title=\"Estimated vs Expected Exposure Term\",label=\"True Exposure\")\nplot!(L̂,label=\"Estimated Exposure\")\nsavefig(\"estimated_exposure.png\")\nsavefig(\"estimated_exposure.pdf\")\n\n# Create an optimizer for the SINDY problem\nopt = SR3()\n# Create the thresholds which should be used in the search process\nthresholds = exp10.(-6:0.1:1)\n\n# Test on original data and without further knowledge\nΨ_direct = SInDy(X[2:4, :], DX[2:4, :], basis, thresholds, opt = opt, maxiter = 50000) # Fail\nprintln(Ψ_direct.basis)\n# Test on ideal derivative data ( not available )\nΨ_ideal = SInDy(X[2:4, 5:end], L[5:end], basis, thresholds, opt = opt, maxiter = 50000) # Succeed\nprintln(Ψ_ideal.basis)\n# Test on uode derivative data\nΨ = SInDy(X̂[:, 2:end], L̂[2:end], basis, thresholds,  opt = opt, maxiter = 10000, normalize = true, denoise = true) # Succeed\nprintln(Ψ.basis)\n\n# Build a ODE for the estimated system\nfunction approx(u,p,t)\n    S,E,I,R,N,D,C = u\n    F, β0,α,κ,μ,σ,γ,d,λ = p_\n    z = Ψ([S/N,I,D/N]) # Exposure does not depend on exposed, removed, or cumulative!\n    dS = -β0*S*F/N - z[1] -μ*S # susceptible\n    dE = β0*S*F/N + z[1] -(σ+μ)*E # exposed\n    dI = σ*E - (γ+μ)*I # infected\n    dR = γ*I - μ*R # removed (recovered + dead)\n    dN = -μ*N # total population\n    dD = d*γ*I - λ*D # severe, critical cases, and deaths\n    dC = σ*E # +cumulative cases\n\n    [dS,dE,dI,dR,dN,dD,dC]\nend\n\n# Create the approximated problem and solution\na_prob = ODEProblem{false}(approx, u0, tspan2, p_)\na_solution = solve(a_prob, Tsit5())\n\np_uodesindy = scatter(solution_extrapolate, vars=[2,3,4], legend = :topleft, label=[\"True Exposed\" \"True Infected\" \"True Recovered\"])\nplot!(p_uodesindy,a_solution, lw = 5, vars=[2,3,4], label=[\"Estimated Exposed\" \"Estimated Infected\" \"Estimated Recovered\"])\nplot!(p_uodesindy,[20.99,21.01],[0.0,maximum(hcat(Array(solution_extrapolate[2:4,:]),Array(_sol_uode[2:4,:])))],lw=5,color=:black,label=\"Training Data End\")\n\nsavefig(\"universalodesindy_extrapolation.png\")\nsavefig(\"universalodesindy_extrapolation.pdf\")"
  },
  {
    "objectID": "index_julia-intro.html",
    "href": "index_julia-intro.html",
    "title": "PART I: Intro. to Julia",
    "section": "",
    "text": "Slides"
  },
  {
    "objectID": "resources.html#basics",
    "href": "resources.html#basics",
    "title": "Resources",
    "section": "Basics",
    "text": "Basics\n\nJulia Documentaion (official doc also includes advanced topics)\nThink Julia\nMATLAB-Python-Julia cheatsheet\nJulia cheatsheet\nThe Julia Express"
  },
  {
    "objectID": "resources.html#advanced-topics",
    "href": "resources.html#advanced-topics",
    "title": "Resources",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nMIT’s 18.337J/6.338J: Parallel Computing and Scientific Machine Learning course. (videos, book)\nA Deep Introduction to Julia for Data Science and Scientific Computing"
  },
  {
    "objectID": "resources.html#community",
    "href": "resources.html#community",
    "title": "Resources",
    "section": "Community",
    "text": "Community\n\nDiscourse\nForum"
  },
  {
    "objectID": "resources.html#packages",
    "href": "resources.html#packages",
    "title": "Resources",
    "section": "Packages",
    "text": "Packages\n\nSurvey of Julia packages"
  },
  {
    "objectID": "resources.html#news",
    "href": "resources.html#news",
    "title": "Resources",
    "section": "News",
    "text": "News\n\nJulia Computing"
  }
]